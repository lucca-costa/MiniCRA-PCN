{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QiRTSGtKV4M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from scipy.spatial import cKDTree\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "import gc\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import struct"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_to_sphere(pc):\n",
        "    centroid = np.mean(pc, axis=0)\n",
        "    pc_centered = pc - centroid\n",
        "    max_distance = np.max(np.linalg.norm(pc_centered, axis=1))\n",
        "    if max_distance == 0:\n",
        "        return pc_centered\n",
        "    pc_normalized = pc_centered / max_distance\n",
        "    return pc_normalized"
      ],
      "metadata": {
        "id": "Owv3zPNWLZPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET\n",
        "\n",
        "class ModelNet40(Dataset):\n",
        "    def __init__(self, root_dir, file_list, mode='train', corruption_rate=0.5, num_points=2048,\n",
        "                 use_curriculum=True, use_augmentation=True):\n",
        "        self.mode = mode\n",
        "        self.num_points = num_points\n",
        "        self.corruption_rate = corruption_rate\n",
        "        self.use_curriculum = use_curriculum\n",
        "        self.use_augmentation = use_augmentation\n",
        "        self.current_epoch = 0\n",
        "        self.data = []\n",
        "\n",
        "        with open(os.path.join(root_dir, file_list), 'r') as f:\n",
        "            h5_files = [os.path.join(root_dir, line.strip()) for line in f]\n",
        "\n",
        "        for h5_file in h5_files:\n",
        "            with h5py.File(h5_file, 'r') as f:\n",
        "                pcds = f['data'][:].astype('float32')\n",
        "                for pcd in pcds:\n",
        "                    pcd_normalized = normalize_to_sphere(pcd)\n",
        "                    self.data.append(pcd_normalized)\n",
        "\n",
        "        self.corrupted_dir = os.path.join(root_dir, \"corrupted_dataset\")\n",
        "        os.makedirs(self.corrupted_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def set_epoch(self, epoch):\n",
        "        self.current_epoch = epoch\n",
        "\n",
        "\n",
        "    def get_current_corruption_rate(self):\n",
        "        if not self.use_curriculum:\n",
        "            return self.corruption_rate\n",
        "\n",
        "        initial_rate = 0.3\n",
        "        final_rate = 0.9\n",
        "        transition_epochs = 100\n",
        "\n",
        "        if self.current_epoch < transition_epochs:\n",
        "            rate = initial_rate + (final_rate - initial_rate) * (self.current_epoch / transition_epochs)\n",
        "        else:\n",
        "            rate = final_rate\n",
        "\n",
        "        return rate\n",
        "\n",
        "\n",
        "    def augment_pointcloud(self, pc):\n",
        "        if not self.use_augmentation or self.mode != 'encoder':\n",
        "            return pc\n",
        "\n",
        "        pc = pc.copy()\n",
        "\n",
        "        # Rotação\n",
        "        if np.random.rand() < 0.7:\n",
        "            theta = np.random.uniform(0, 2 * np.pi)\n",
        "            cos_theta = np.cos(theta)\n",
        "            sin_theta = np.sin(theta)\n",
        "            rot_matrix = np.array([\n",
        "                [cos_theta, -sin_theta, 0],\n",
        "                [sin_theta, cos_theta, 0],\n",
        "                [0, 0, 1]\n",
        "            ], dtype=np.float32)\n",
        "            pc = pc @ rot_matrix.T\n",
        "\n",
        "        if np.random.rand() < 0.3:\n",
        "            angle_x = np.random.uniform(-np.pi/12, np.pi/12)\n",
        "            angle_y = np.random.uniform(-np.pi/12, np.pi/12)\n",
        "\n",
        "            rot_x = np.array([\n",
        "                [1, 0, 0],\n",
        "                [0, np.cos(angle_x), -np.sin(angle_x)],\n",
        "                [0, np.sin(angle_x), np.cos(angle_x)]\n",
        "            ], dtype=np.float32)\n",
        "            rot_y = np.array([\n",
        "                [np.cos(angle_y), 0, np.sin(angle_y)],\n",
        "                [0, 1, 0],\n",
        "                [-np.sin(angle_y), 0, np.cos(angle_y)]\n",
        "            ], dtype=np.float32)\n",
        "\n",
        "            pc = pc @ rot_x.T @ rot_y.T\n",
        "\n",
        "        # Ruído, scaling e flipping\n",
        "        if np.random.rand() < 0.5:\n",
        "            jitter = np.random.normal(0, 0.01, pc.shape).astype(np.float32)\n",
        "            pc += jitter\n",
        "\n",
        "        if np.random.rand() < 0.3:\n",
        "            scale = np.random.uniform(0.95, 1.05)\n",
        "            pc *= scale\n",
        "\n",
        "        if np.random.rand() < 0.2:\n",
        "            pc[:, 0] *= -1\n",
        "\n",
        "        return pc\n",
        "\n",
        "\n",
        "    def corrupt_pointcloud(self, pc, idx, corruption_rate=None):\n",
        "        if corruption_rate is None:\n",
        "            corruption_rate = self.get_current_corruption_rate()\n",
        "\n",
        "        seed = idx + self.current_epoch * 100000\n",
        "        rng = np.random.default_rng(seed)\n",
        "        num_points = pc.shape[0]\n",
        "        num_to_remove = int(corruption_rate * num_points)\n",
        "\n",
        "        if num_to_remove == 0:\n",
        "            return pc\n",
        "\n",
        "        tree = cKDTree(pc)\n",
        "        mask = np.ones(num_points, dtype=bool)\n",
        "        available_indices = np.arange(num_points)\n",
        "        removed = 0\n",
        "\n",
        "        while removed < num_to_remove and len(available_indices) > 0:\n",
        "            seed_idx = rng.choice(available_indices)\n",
        "            K = rng.integers(5, 64)\n",
        "            distances, neighbor_indices = tree.query(pc[seed_idx], k=min(K, len(available_indices)))\n",
        "\n",
        "            if not isinstance(neighbor_indices, np.ndarray):\n",
        "                neighbor_indices = [neighbor_indices]\n",
        "\n",
        "            to_remove = []\n",
        "            for n_idx in neighbor_indices:\n",
        "                if mask[n_idx]:\n",
        "                    to_remove.append(n_idx)\n",
        "                    removed += 1\n",
        "                    if removed >= num_to_remove:\n",
        "                        break\n",
        "\n",
        "            mask[to_remove] = False\n",
        "            available_indices = np.where(mask)[0]\n",
        "\n",
        "        corrupted_pc = pc[mask]\n",
        "        return corrupted_pc\n",
        "\n",
        "\n",
        "    # FUNÇÃO BIG IMPORTANTE\n",
        "    def __getitem__(self, idx):\n",
        "        original_pc = self.data[idx]\n",
        "\n",
        "        if self.use_augmentation and self.mode == 'encoder':\n",
        "            original_pc = self.augment_pointcloud(original_pc)\n",
        "\n",
        "        if self.mode == 'encoder':\n",
        "            corrupted_pc = self.corrupt_pointcloud(original_pc, idx)\n",
        "\n",
        "            padded_pc = np.zeros((self.num_points, 3), dtype=np.float32)\n",
        "            padded_pc[:corrupted_pc.shape[0]] = corrupted_pc\n",
        "            return torch.tensor(padded_pc).float(), torch.tensor(original_pc).float()\n",
        "        else:\n",
        "            return torch.tensor(original_pc).float()"
      ],
      "metadata": {
        "id": "_74KWv_OKucV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_grouping(xyz, features, k=16):\n",
        "    B, N, C = features.shape\n",
        "\n",
        "    dist = torch.cdist(xyz, xyz)\n",
        "    _, idx = torch.topk(dist, k, dim=-1, largest=False)\n",
        "\n",
        "    idx_expanded = idx.unsqueeze(-1).expand(-1, -1, -1, C)\n",
        "    features_expanded = features.unsqueeze(2).expand(-1, -1, k, -1)\n",
        "\n",
        "    batch_idx = torch.arange(B, device=features.device).view(B, 1, 1, 1).expand(B, N, k, C)\n",
        "    feat_idx = torch.arange(C, device=features.device).view(1, 1, 1, C).expand(B, N, k, C)\n",
        "\n",
        "    neighbor_features = features[batch_idx, idx_expanded, feat_idx]\n",
        "\n",
        "    return neighbor_features, idx"
      ],
      "metadata": {
        "id": "_bGBMsoZR7hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalAggregation(nn.Module):\n",
        "    def __init__(self, dim=128, k=16):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "\n",
        "        # attention\n",
        "        self.query_conv = nn.Conv1d(dim, dim, 1)\n",
        "        self.key_conv = nn.Conv1d(dim, dim, 1)\n",
        "        self.value_conv = nn.Conv1d(dim, dim, 1)\n",
        "\n",
        "        self.pos_mlp = nn.Sequential(\n",
        "            nn.Conv2d(3, dim, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(dim, dim, 1)\n",
        "        )\n",
        "\n",
        "        self.out_conv = nn.Conv1d(dim, dim, 1)\n",
        "\n",
        "\n",
        "    def forward(self, xyz, features):\n",
        "        B, N, C = features.shape\n",
        "        feat = features.transpose(1, 2)\n",
        "        neighbor_features, idx = knn_grouping(xyz, features, self.k)\n",
        "\n",
        "        batch_idx = torch.arange(B, device=xyz.device).view(B, 1, 1, 1).expand(B, N, self.k, 3)\n",
        "        idx_xyz = idx.unsqueeze(-1).expand(-1, -1, -1, 3)\n",
        "        pos_idx = torch.arange(3, device=xyz.device).view(1, 1, 1, 3).expand(B, N, self.k, 3)\n",
        "        neighbor_xyz = xyz[batch_idx, idx_xyz, pos_idx]\n",
        "\n",
        "        pos_rel = (xyz.unsqueeze(2) - neighbor_xyz).permute(0, 3, 1, 2)\n",
        "        pos_enc = self.pos_mlp(pos_rel)\n",
        "\n",
        "        q = self.query_conv(feat).unsqueeze(-1)\n",
        "        k = neighbor_features.permute(0, 3, 1, 2) + pos_enc\n",
        "        v = neighbor_features.permute(0, 3, 1, 2) + pos_enc\n",
        "\n",
        "        attn = torch.sum(q * k, dim=1, keepdim=True) / (C ** 0.5)\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "        out = torch.sum(attn * v, dim=-1)\n",
        "        out = self.out_conv(out)\n",
        "\n",
        "        return out.transpose(1, 2) + features"
      ],
      "metadata": {
        "id": "U9epjosMSU1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=512):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, 1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(64, 128, 1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.local_agg = LocalAggregation(dim=128, k=16)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv1d(128, 256, 1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv1d(256, latent_dim, 1),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        xyz = x\n",
        "\n",
        "        x = self.conv1(x.transpose(1, 2))\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        x = self.local_agg(xyz, x.transpose(1, 2))\n",
        "\n",
        "        x = self.conv3(x.transpose(1, 2))\n",
        "        point_feat = x.transpose(1, 2)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        global_feat = torch.max(x, dim=2)[0]\n",
        "\n",
        "        return global_feat, point_feat"
      ],
      "metadata": {
        "id": "oVGGofmETHm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CoarseSeedGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim=512, num_coarse=256):\n",
        "        super().__init__()\n",
        "        self.num_coarse = num_coarse\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_coarse * 3)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, global_feat):\n",
        "        coarse = self.mlp(global_feat)\n",
        "        return coarse.view(-1, self.num_coarse, 3)"
      ],
      "metadata": {
        "id": "bQZdHyCqTu-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Upsampler(nn.Module):\n",
        "    def __init__(self, feat_dim=512, up_factor=2):\n",
        "        super().__init__()\n",
        "        self.up_factor = up_factor\n",
        "\n",
        "        self.feat_mlp = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 128, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.combine = nn.Sequential(\n",
        "            nn.Conv1d(128 + feat_dim, 256, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(256, 128, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.local_agg = LocalAggregation(dim=128, k=8)\n",
        "\n",
        "        self.up_mlp = nn.Sequential(\n",
        "            nn.Conv1d(128, 64, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 3 * up_factor, 1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, xyz, global_feat):\n",
        "        B, N, _ = xyz.shape\n",
        "        feat = self.feat_mlp(xyz.transpose(1, 2))\n",
        "\n",
        "        global_expanded = global_feat.unsqueeze(2).expand(-1, -1, N)\n",
        "\n",
        "        combined = self.combine(torch.cat([feat, global_expanded], dim=1))\n",
        "\n",
        "        refined = self.local_agg(xyz, combined.transpose(1, 2))\n",
        "\n",
        "        offsets = self.up_mlp(refined.transpose(1, 2))\n",
        "        offsets = offsets.view(B, 3, self.up_factor, N).permute(0, 3, 2, 1)\n",
        "\n",
        "        xyz_expanded = xyz.unsqueeze(2).expand(-1, -1, self.up_factor, -1)\n",
        "        new_xyz = xyz_expanded + 0.1 * torch.tanh(offsets)\n",
        "\n",
        "        return new_xyz.reshape(B, N * self.up_factor, 3)"
      ],
      "metadata": {
        "id": "sD0UR2RsT9pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniCRAPCN(nn.Module):\n",
        "    def __init__(self, num_points=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(latent_dim=512)\n",
        "\n",
        "        self.seed_generator = CoarseSeedGenerator(latent_dim=512, num_coarse=256)\n",
        "\n",
        "        self.up1 = Upsampler(feat_dim=512, up_factor=2)\n",
        "        self.up2 = Upsampler(feat_dim=512, up_factor=2)\n",
        "        self.up3 = Upsampler(feat_dim=512, up_factor=2)\n",
        "\n",
        "\n",
        "    def forward(self, partial):\n",
        "        global_feat, _ = self.encoder(partial)\n",
        "\n",
        "        coarse = self.seed_generator(global_feat)\n",
        "\n",
        "        fine1 = self.up1(coarse, global_feat)\n",
        "        fine2 = self.up2(fine1, global_feat)\n",
        "        fine3 = self.up3(fine2, global_feat)\n",
        "\n",
        "        return [coarse, fine1, fine2, fine3]"
      ],
      "metadata": {
        "id": "MIdoz6-HUj_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_padding(padded_pc):\n",
        "    batch_list = []\n",
        "\n",
        "    for pc in padded_pc:\n",
        "        mask = torch.sum(torch.abs(pc), dim=1) > 1e-6\n",
        "        valid_pc = pc[mask]\n",
        "        if len(valid_pc) == 0:\n",
        "            valid_pc = pc[:1]\n",
        "        batch_list.append(valid_pc)\n",
        "    return batch_list\n",
        "\n",
        "\n",
        "def collate_fn_remove_padding(batch):\n",
        "    padded_partials, completes = zip(*batch)\n",
        "\n",
        "    completes = torch.stack(completes, dim=0)\n",
        "    partials_list = remove_padding(torch.stack(padded_partials, dim=0))\n",
        "\n",
        "    return partials_list, completes\n",
        "\n",
        "\n",
        "def chamfer_distance(pred, gt):\n",
        "    B = pred.size(0)\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(B):\n",
        "        p = pred[i:i+1]\n",
        "        g = gt[i:i+1]\n",
        "\n",
        "        diff = p.unsqueeze(2) - g.unsqueeze(1)\n",
        "        dist = torch.sum(diff ** 2, dim=3)\n",
        "\n",
        "        dist1, _ = torch.min(dist, dim=2)\n",
        "\n",
        "        dist2, _ = torch.min(dist, dim=1)\n",
        "\n",
        "        total_loss += torch.mean(dist1) + torch.mean(dist2)\n",
        "\n",
        "    return total_loss / B\n",
        "\n",
        "\n",
        "def multi_scale_loss(pred_list, gt):\n",
        "    weights = [2.0, 1.5, 1.0, 0.5]\n",
        "    total_loss = 0\n",
        "\n",
        "    for pred, w in zip(pred_list, weights):\n",
        "        loss = chamfer_distance(pred, gt)\n",
        "        total_loss += w * loss\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "Y3DaYmClQmPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mini_crapcn(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs=200,\n",
        "    learning_rate=0.0001,\n",
        "    checkpoint_dir='/content/drive/MyDrive/checkpoints',\n",
        "    device='cuda',\n",
        "    save_frequency=10,\n",
        "    val_frequency=5\n",
        "):\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Training MiniCRAPCN\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "    print(f\"Checkpoint dir: {checkpoint_dir}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if hasattr(train_loader.dataset, 'set_epoch'):\n",
        "            train_loader.dataset.set_epoch(epoch)\n",
        "            current_corruption = train_loader.dataset.get_current_corruption_rate()\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs} - Corruption Rate: {current_corruption:.2%}\")\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_start = time.time()\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for batch_idx, (partials_list, completes) in enumerate(pbar):\n",
        "            completes = completes.to(device)\n",
        "            batch_size = len(partials_list)\n",
        "            batch_loss = 0\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                partial = partials_list[i].unsqueeze(0).to(device)\n",
        "                complete = completes[i:i+1]\n",
        "                pred_list = model(partial)\n",
        "\n",
        "                loss = multi_scale_loss(pred_list, complete)\n",
        "                batch_loss += loss\n",
        "\n",
        "            batch_loss = batch_loss / batch_size\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            epoch_loss += batch_loss.item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{batch_loss.item():.6f}',\n",
        "                'avg_loss': f'{epoch_loss/(batch_idx+1):.6f}'\n",
        "            })\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.6f} - Time: {epoch_time:.1f}s - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "        if (epoch + 1) % val_frequency == 0 and val_loader is not None:\n",
        "            val_loss = validate(model, val_loader, device)\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"Validation Loss: {val_loss:.6f}\")\n",
        "\n",
        "            # best model\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                save_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'val_loss': val_loss,\n",
        "                    'train_loss': avg_train_loss\n",
        "                }, save_path)\n",
        "                print(f\"✓ Saved best model (val_loss: {val_loss:.6f})\")\n",
        "\n",
        "        if (epoch + 1) % save_frequency == 0:\n",
        "            save_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'scheduler_state_dict': scheduler.state_dict()\n",
        "            }, save_path)\n",
        "            print(f\"✓ Saved checkpoint\")\n",
        "\n",
        "        scheduler.step()\n",
        "        print()\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Training completed!\")\n",
        "    print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "\n",
        "def validate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for partials_list, completes in val_loader:\n",
        "            completes = completes.to(device)\n",
        "            batch_size = len(partials_list)\n",
        "\n",
        "            batch_loss = 0\n",
        "            for i in range(batch_size):\n",
        "                partial = partials_list[i].unsqueeze(0).to(device)\n",
        "                complete = completes[i:i+1]\n",
        "\n",
        "                pred_list = model(partial)\n",
        "                loss = multi_scale_loss(pred_list, complete)\n",
        "                batch_loss += loss\n",
        "\n",
        "            val_loss += (batch_loss / batch_size).item()\n",
        "\n",
        "    return val_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "2sqqmvZeVvmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_zip_path = \"/content/drive/MyDrive/ADONestDataset/data.zip\"\n",
        "local_zip_path = \"/content/data.zip\"\n",
        "local_data_root = \"/content/data/modelnet40_ply_hdf5_2048\"\n",
        "extraction_path = \"/content/\"\n",
        "\n",
        "print(\"Verificando o dataset...\")\n",
        "if not os.path.exists(local_data_root):\n",
        "    print(f\"Dataset não encontrado em {local_data_root}.\")\n",
        "\n",
        "    print(f\"Copiando {drive_zip_path} para a VM local...\")\n",
        "    shutil.copy(drive_zip_path, local_zip_path)\n",
        "    print(\"Cópia do ZIP concluída.\")\n",
        "\n",
        "    print(f\"Extraindo {local_zip_path} para {extraction_path}...\")\n",
        "    !unzip -q {local_zip_path} -d {extraction_path}\n",
        "    print(\"Extração concluída.\")\n",
        "\n",
        "    print(f\"Removendo arquivo ZIP local: {local_zip_path}\")\n",
        "    os.remove(local_zip_path)\n",
        "    print(\"Limpeza concluída.\")\n",
        "else:\n",
        "    print(f\"Dataset já existe em {local_data_root}\")\n",
        "\n",
        "train_file_list = \"train_files.txt\"\n",
        "val_file_list = \"test_files.txt\""
      ],
      "metadata": {
        "id": "Yt4WEVbtW32s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros\n",
        "\n",
        "BATCH_SIZE = 128 + 32\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(DEVICE)\n",
        "NUM_WORKERS = 4\n",
        "CORRUPTION_RATE = 0.5\n",
        "NUM_EPOCHS = 200\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_POINTS = 2048\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/checkpoints_new_v1_2'"
      ],
      "metadata": {
        "id": "DGuDMM1QXG-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instancia datasets\n",
        "\n",
        "train_dataset = ModelNet40(\n",
        "    root_dir=local_data_root,\n",
        "    file_list='train_files.txt',\n",
        "    mode='encoder',\n",
        "    corruption_rate=0.5,\n",
        "    num_points=NUM_POINTS,\n",
        "    use_curriculum=True,\n",
        "    use_augmentation=True\n",
        ")\n",
        "\n",
        "val_dataset = ModelNet40(\n",
        "    root_dir=local_data_root,\n",
        "    file_list='test_files.txt',\n",
        "    mode='encoder',\n",
        "    corruption_rate=0.7,\n",
        "    num_points=NUM_POINTS,\n",
        "    use_curriculum=False,\n",
        "    use_augmentation=False\n",
        ")\n",
        "\n",
        "val_size = len(train_dataset)\n",
        "val_size = val_size - test_size\n",
        "\n",
        "indices = np.random.permutation(len(val_dataset))\n",
        "val_indices = indices[:val_size]\n",
        "\n",
        "train_dataset = train_dataset\n",
        "val_dataset = Subset(val_dataset, val_indices)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "I-YCQ8E5XLeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn_remove_padding,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn_remove_padding,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "l-lEFkQEXWCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear cache\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "OrDL-5UQXZws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MiniCRAPCN(num_points=NUM_POINTS)\n",
        "\n",
        "# Train\n",
        "train_losses, val_losses = train_mini_crapcn(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    checkpoint_dir=CHECKPOINT_DIR,\n",
        "    device=device,\n",
        "    save_frequency=2,\n",
        "    val_frequency=5\n",
        ")"
      ],
      "metadata": {
        "id": "-utZiZ7lX1cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    if val_losses:\n",
        "        val_epochs = [i * 5 for i in range(len(val_losses))]\n",
        "        plt.plot(val_epochs, val_losses, label='Val Loss', marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training Progress')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_curve.png'))\n",
        "    plt.show()\n",
        "    print(f\"Saved training curve to {CHECKPOINT_DIR}/training_curve.png\")\n",
        "except:\n",
        "    print(\"Could not plot (matplotlib not available or not in notebook)\")"
      ],
      "metadata": {
        "id": "b_IexEs4X7Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ply(points: np.ndarray, filepath: str):\n",
        "    N = points.shape[0]\n",
        "\n",
        "    header = f\"\"\"ply\n",
        "format binary_little_endian 1.0\n",
        "element vertex {N}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "end_header\n",
        "\"\"\"\n",
        "\n",
        "    with open(filepath, 'wb') as f:\n",
        "        f.write(header.encode('ascii'))\n",
        "        for point in points:\n",
        "            f.write(struct.pack('fff', point[0], point[1], point[2]))\n",
        "\n",
        "\n",
        "def inference_to_zip(\n",
        "    checkpoint_path: str,\n",
        "    test_loader: torch.utils.data.DataLoader,\n",
        "    output_zip: str = 'predictions_mini_crapcn.zip',\n",
        "    device: str = 'cuda',\n",
        "    use_finest: bool = True,\n",
        "    save_all_scales: bool = False\n",
        "):\n",
        "\n",
        "    model = MiniCRAPCN(num_points=2048).to(device)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    epoch = checkpoint.get('epoch', 'unknown')\n",
        "    val_loss = checkpoint.get('val_loss', checkpoint.get('train_loss', 'unknown'))\n",
        "    print(f\" Epoch: {epoch}\")\n",
        "    print(f\"  Checkpoint loss: {val_loss}\")\n",
        "\n",
        "    temp_dir = Path('temp_ply_crapcn')\n",
        "    temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    sample_idx = 0\n",
        "\n",
        "    print(f\"  Saving {'all scales' if save_all_scales else 'finest scale only'}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Processing\"):\n",
        "            if isinstance(batch, (tuple, list)):\n",
        "                if isinstance(batch[0], list):\n",
        "                    partials_list = batch[0]\n",
        "                    batch_size = len(partials_list)\n",
        "                else:\n",
        "                    partials = batch[0].to(device)\n",
        "                    batch_size = partials.shape[0]\n",
        "                    partials_list = [partials[i] for i in range(batch_size)]\n",
        "            else:\n",
        "                partials = batch.to(device)\n",
        "                batch_size = partials.shape[0]\n",
        "                partials_list = [partials[i] for i in range(batch_size)]\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                partial = partials_list[i].unsqueeze(0).to(device)\n",
        "\n",
        "                pred_list = model(partial)\n",
        "\n",
        "                if save_all_scales:\n",
        "                    scale_names = ['coarse_256', 'fine1_512', 'fine2_1024', 'fine3_2048']\n",
        "                    for scale_idx, (pred, scale_name) in enumerate(zip(pred_list, scale_names)):\n",
        "                        pred_points = pred[0].cpu().numpy()\n",
        "                        pred_file = temp_dir / f'prediction_{sample_idx:06d}_{scale_name}.ply'\n",
        "                        save_ply(pred_points, str(pred_file))\n",
        "                else:\n",
        "                    if use_finest:\n",
        "                        pred_points = pred_list[-1][0].cpu().numpy()\n",
        "                    else:\n",
        "                        pred_points = pred_list[0][0].cpu().numpy()\n",
        "\n",
        "                    pred_file = temp_dir / f'prediction_{sample_idx:06d}.ply'\n",
        "                    save_ply(pred_points, str(pred_file))\n",
        "\n",
        "                sample_idx += 1\n",
        "\n",
        "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        ply_files = sorted(temp_dir.glob('*.ply'))\n",
        "        for ply_file in tqdm(ply_files, desc=\"Zipping\"):\n",
        "            zipf.write(ply_file, ply_file.name)\n",
        "\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    zip_size = Path(output_zip).stat().st_size / (1024**2)\n",
        "    files_per_sample = 4 if save_all_scales else 1\n",
        "    print(f\"\\n Inference complete!\")\n",
        "    print(f\"  Samples processed: {sample_idx}\")\n",
        "    print(f\"  Files created: {sample_idx * files_per_sample}\")\n",
        "    print(f\"  Output: {output_zip}\")\n",
        "    print(f\"  Zip size: {zip_size:.1f} MB\")\n",
        "\n",
        "    return sample_idx\n",
        "\n",
        "\n",
        "def quick_visual_check(\n",
        "    checkpoint_path: str,\n",
        "    test_loader: torch.utils.data.DataLoader,\n",
        "    num_samples: int = 5,\n",
        "    device: str = 'cuda'\n",
        "):\n",
        "\n",
        "    model = MiniCRAPCN(num_points=2048).to(device)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    print(\" Quick visual check (first few samples):\\n\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch = next(iter(test_loader))\n",
        "\n",
        "        if isinstance(batch, (tuple, list)):\n",
        "            if isinstance(batch[0], list):\n",
        "                partials_list = batch[0][:num_samples]\n",
        "            else:\n",
        "                partials = batch[0].to(device)[:num_samples]\n",
        "                partials_list = [partials[i] for i in range(min(num_samples, partials.shape[0]))]\n",
        "        else:\n",
        "            partials = batch.to(device)[:num_samples]\n",
        "            partials_list = [partials[i] for i in range(min(num_samples, partials.shape[0]))]\n",
        "\n",
        "        for i, partial in enumerate(partials_list):\n",
        "            partial = partial.unsqueeze(0).to(device)\n",
        "            pred_list = model(partial)\n",
        "\n",
        "            print(f\"Sample {i+1}:\")\n",
        "            print(f\"  Input shape: {partial.shape} ({partial.shape[1]} points)\")\n",
        "            print(f\"  Coarse (256):  mean={pred_list[0][0].mean():.3f}, std={pred_list[0][0].std():.3f}\")\n",
        "            print(f\"  Fine1 (512):   mean={pred_list[1][0].mean():.3f}, std={pred_list[1][0].std():.3f}\")\n",
        "            print(f\"  Fine2 (1024):  mean={pred_list[2][0].mean():.3f}, std={pred_list[2][0].std():.3f}\")\n",
        "            print(f\"  Fine3 (2048):  mean={pred_list[3][0].mean():.3f}, std={pred_list[3][0].std():.3f}\")\n",
        "\n",
        "            if torch.isnan(pred_list[-1]).any():\n",
        "                print(\"WARNING: NaN values detected!\")\n",
        "            if torch.isinf(pred_list[-1]).any():\n",
        "                print(\"WARNING: Inf values detected!\")\n",
        "\n",
        "            print()"
      ],
      "metadata": {
        "id": "jMt18uGHaxYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Full Inference\")\n",
        "print(\"=\"*60)\n",
        "num_samples = inference_to_zip(\n",
        "    checkpoint_path='best_model_v1_2.pth',\n",
        "    test_loader=val_loader,\n",
        "    output_zip='predictions_mini_crapcn1_2.zip',\n",
        "    device='cuda',\n",
        "    use_finest=True,\n",
        "    save_all_scales=False\n",
        ")\n",
        "\n",
        "print(f\"\\n All done! Processed {num_samples} samples\")\n"
      ],
      "metadata": {
        "id": "cDeTyu5adGDs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}